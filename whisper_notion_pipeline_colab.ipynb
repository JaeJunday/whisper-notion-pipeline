{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Whisper ìŒì„± ì „ì‚¬ ë„êµ¬\n\n**ê°„ë‹¨í•œ 4ë‹¨ê³„ ì‹¤í–‰:**\n1. íŒ¨í‚¤ì§€ ì„¤ì¹˜\n2. Google Drive ë§ˆìš´íŠ¸\n3. ì„¤ì • ë° í•¨ìˆ˜ ì •ì˜\n4. ì‹¤í–‰\n\nê²°ê³¼ëŠ” Google Driveì˜ `whisper_notion_pipeline/output` í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# 1ë‹¨ê³„: íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° GPU í™•ì¸\n!nvidia-smi\n%pip install -q openai-whisper\n\nimport torch\nprint(f\"\\nGPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU ì´ë¦„: {torch.cuda.get_device_name(0)}\")"
  },
  {
   "cell_type": "code",
   "source": "# 2ë‹¨ê³„: Google Drive ë§ˆìš´íŠ¸\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nimport os\nWORK_DIR = '/content/drive/MyDrive/whisper_notion_pipeline'\nos.makedirs(WORK_DIR, exist_ok=True)\nos.makedirs(f'{WORK_DIR}/input', exist_ok=True)\nos.makedirs(f'{WORK_DIR}/output', exist_ok=True)\n\nprint(f\"ì‘ì—… ë””ë ‰í† ë¦¬: {WORK_DIR}\")\nprint(\"âœ“ input í´ë”ì— ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 3ë‹¨ê³„: ì„¤ì • ë° í•¨ìˆ˜ ì •ì˜\nimport whisper\nimport json\nimport time\nfrom pathlib import Path\nimport glob\n\n# Whisper ëª¨ë¸ ì„¤ì •\nMODEL_NAME = \"base\"  # tiny, base, small, medium, large\nLANGUAGE = \"ko\"  # ì–¸ì–´ ì„¤ì •\n\ndef process_audio_file(audio_path):\n    \"\"\"ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\"\"\"\n    audio_path = Path(audio_path)\n    \n    # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ í™•ì¸\n    output_dir = Path(f\"{WORK_DIR}/output/{audio_path.stem}\")\n    if output_dir.exists() and (output_dir / \"transcript.txt\").exists():\n        print(f\"â­ï¸  ì´ë¯¸ ì²˜ë¦¬ë¨: {audio_path.name}\")\n        return None\n    \n    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n    output_dir.mkdir(parents=True, exist_ok=True)\n    \n    print(f\"\\n{'='*50}\")\n    print(f\"ğŸ¤ ì²˜ë¦¬ ì‹œì‘: {audio_path.name}\")\n    print(f\"{'='*50}\")\n    \n    # Whisper ëª¨ë¸ ë¡œë“œ ë° ì „ì‚¬\n    print(\"ğŸ”„ Whisper ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n    model = whisper.load_model(MODEL_NAME, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {MODEL_NAME}\")\n    \n    print(f\"\\nğŸ§ ì˜¤ë””ì˜¤ ì „ì‚¬ ì‹œì‘...\")\n    start_time = time.time()\n    \n    # ì§„í–‰ ìƒí™©ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•´ verbose=True ì¶”ê°€\n    result = model.transcribe(\n        str(audio_path), \n        language=LANGUAGE,\n        verbose=True,  # ì§„í–‰ ìƒí™© í‘œì‹œ\n        fp16=torch.cuda.is_available()  # GPU ì‚¬ìš© ì‹œ ë” ë¹ ë¥¸ ì²˜ë¦¬\n    )\n    \n    elapsed_time = time.time() - start_time\n    print(f\"\\nâœ“ ì „ì‚¬ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ)\")\n    \n    # ê²°ê³¼ ì €ì¥\n    print(f\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...\")\n    with open(output_dir / \"transcript.txt\", \"w\", encoding=\"utf-8\") as f:\n        f.write(result['text'])\n    \n    with open(output_dir / \"report.json\", \"w\", encoding=\"utf-8\") as f:\n        json.dump({\n            \"file_name\": audio_path.name,\n            \"text\": result['text'],\n            \"language\": result['language'],\n            \"duration\": f\"{elapsed_time:.1f}ì´ˆ\"\n        }, f, ensure_ascii=False, indent=2)\n    \n    print(f\"âœ“ ì €ì¥ ì™„ë£Œ: {output_dir}\")\n    print(f\"\\nğŸ“ ì „ì‚¬ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°:\")\n    print(f\"   {result['text'][:100]}...\" if len(result['text']) > 100 else f\"   {result['text']}\")\n    \n    return result\n\nprint(\"âœ“ ì„¤ì • ì™„ë£Œ\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 4ë‹¨ê³„: ì‹¤í–‰ - ëª¨ë“  ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬\naudio_extensions = ['*.mp3', '*.m4a', '*.wav', '*.flac', '*.ogg']\naudio_files = []\n\nfor ext in audio_extensions:\n    audio_files.extend(glob.glob(f\"{WORK_DIR}/input/{ext}\"))\n\nif audio_files:\n    print(f\"ğŸ” ë°œê²¬ëœ íŒŒì¼: {len(audio_files)}ê°œ\")\n    for i, file in enumerate(audio_files, 1):\n        print(f\"   {i}. {os.path.basename(file)}\")\n    \n    print(f\"\\nğŸš€ ì „ì²´ ì²˜ë¦¬ ì‹œì‘...\\n\")\n    total_start = time.time()\n    \n    for idx, audio_file in enumerate(audio_files, 1):\n        print(f\"\\n[{idx}/{len(audio_files)}] íŒŒì¼ ì²˜ë¦¬\")\n        process_audio_file(audio_file)\n    \n    total_time = time.time() - total_start\n    print(f\"\\n{'='*50}\")\n    print(f\"âœ… ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!\")\n    print(f\"   ì´ ì†Œìš” ì‹œê°„: {total_time:.1f}ì´ˆ\")\n    print(f\"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_time/len(audio_files):.1f}ì´ˆ/íŒŒì¼\")\n    print(f\"{'='*50}\")\nelse:\n    print(\"âŒ input í´ë”ì— ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n    print(f\"   ê²½ë¡œ: {WORK_DIR}/input/\")",
   "metadata": {},
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}